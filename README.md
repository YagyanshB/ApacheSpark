# WTF is Apache Spark? 

Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.

# Key Reasons for Use: 

1. Large Scale Data Processing:
It allows us to handle datasets containing terabytes or petabytes of information. It performs this by performing parallel processing across multiple machines.

 2. Unified Platform:
It supports multiple workloads, including batch processing, streaming, machine learning, and graph processing, and has APIs for different programming languages, such as Python, SQL, Scala, and R.

# Repo Information: 

This repository will contain code on implementing Apache Spark learnt from the medium of YouTube tutorials, online certifications and technical articles. 
